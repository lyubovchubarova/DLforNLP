{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0fOWhqwW-AT"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install seaborn\n",
        "!pip install numpy\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wugeOHW-AV",
        "outputId": "220b5ba8-3945-454c-ab78-de647255f824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9XIrxSmW-AX"
      },
      "source": [
        "# Скачиваем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep1FB3IBW-AY",
        "outputId": "3aef8da2-dcc8-43a4-fc91-2471969ad02e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 09:29:13--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M   120MB/s    in 0.2s    \n",
            "\n",
            "2022-12-02 09:29:15 (120 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BWA7IClKW-Aa"
      },
      "outputs": [],
      "source": [
        "# если ругается на то, что нет wget\n",
        "# !apt-get install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJpFTPpsW-Ac",
        "outputId": "1f920920-39bc-4bf4-9aba-3f57b60fb3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28052\n",
            "-rw-r--r-- 1 root root 28717126 Dec  2 09:29 answers_subsample.csv\n",
            "drwxr-xr-x 1 root root     4096 Nov 23 14:31 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qmzaEwy9W-Ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BbDKxq4EW-Ag"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "hcAdsbS7W-Ai",
        "outputId": "9748827c-76af-4b8f-a11e-f91bf16690b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62794ed3-189e-4bf1-8b91-2fc863a37a53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62794ed3-189e-4bf1-8b91-2fc863a37a53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62794ed3-189e-4bf1-8b91-2fc863a37a53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62794ed3-189e-4bf1-8b91-2fc863a37a53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tXLjfsW-Aj",
        "outputId": "9b48f9a6-f96f-417b-820c-aac92b79b2a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfHbifWIW-Al"
      },
      "source": [
        "# Предобученные эмбеддинги\n",
        "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
        "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
        "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVhCzM3LW-Al",
        "outputId": "3316d7f2-bb6f-4063-9c2d-e0f9d4260401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 09:29:27--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  1.23MB/s    in 64s     \n",
            "\n",
            "2022-12-02 09:30:32 (19.4 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eJcT1qPZW-An",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0243eb8b-e794-4cb0-d4ab-8465743a54d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4458144\n",
            "-rw-r--r-- 1 root root   28717126 Dec  2 09:29 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Nov 23 14:31 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M0lwyZUFW-Ap"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QQpX51Y4W-Aq"
      },
      "outputs": [],
      "source": [
        "# потом можете добавить свою предобработку\n",
        "\n",
        "def process_text(text):\n",
        "    \n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "    \n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HyI2erCDW-Ar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1b17df-a8b8-4194-93d7-c19d4b8595a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [00:01<00:00, 120796.49it/s]\n"
          ]
        }
      ],
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "    \n",
        "    words = process_text(text)\n",
        "    \n",
        "    lengths.append(len(words))\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FGzDm0ptW-At"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iZBR-aYDW-Av",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "247015d2-1ddc-4669-ae5f-68b88767ae01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe1c69a4ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OBzmPqXIW-Aw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91e050ca-644c-44fa-a871-bd2d4613dfa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths \n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GbSer_0bW-Ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc57d17-15ef-4bc0-cb10-25ed6db2e0ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(word2freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "szg6XD3EW-Az",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "outputId": "df518955-a247-43b3-b00c-d8beb4ff5084"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZbOg0FqW-A1"
      },
      "source": [
        "# Читаем файл с эмбеддингами\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "Поэтому прочитаем только те слова, которые мы знаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "T1Yx_qr-W-A2"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLEgfnaWW-A4",
        "outputId": "9a5f8fe9-f143-43b9-8392-54e056ff31d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [00:49<00:00, 40337.22it/s]\n"
          ]
        }
      ],
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYJMzgpnW-A7",
        "outputId": "f2f0fc5e-f2e1-40ae-a7b0-27f544333dd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE06fafiW-A8",
        "outputId": "b79f6bf7-25a3-42e8-ba5b-14d1d317e0cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ],
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFPNApUjW-A9"
      },
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_fo1fB6JW-A-"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEKAjCg3W-BA"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "D19pDyQBW-BA"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Yxsxr7edW-BB"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZy0lKr2W-BC",
        "outputId": "14bd7bd6-493c-4f76-de1e-088f16f7d85a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "540 ms ± 14 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s611e34SW-BE"
      },
      "source": [
        "# А что GPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjFlWdgtW-BE",
        "outputId": "3836aaa1-8e77-4832-f8b3-ecead3177521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доступна ли видеокарта: True\n",
            "Если недоступна, поменяйте runtime, если в колабе\n"
          ]
        }
      ],
      "source": [
        "print('Доступна ли видеокарта:', torch.cuda.is_available())\n",
        "print('Если недоступна, поменяйте runtime, если в колабе')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jaMMD5CDW-BG"
      },
      "outputs": [],
      "source": [
        "# универсальных способ задать device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GeQCiSYdW-BH"
      },
      "outputs": [],
      "source": [
        "# перенесли x на gpu\n",
        "x_gpu = x.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "S_qUdMcbW-BJ"
      },
      "outputs": [],
      "source": [
        "# зададим lstm на gpu\n",
        "lstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "lstm_gpu = lstm_gpu.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSUQmRgtW-BK",
        "outputId": "6d68c713-1553-4401-d8b5-d152cb68d436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.39 ms ± 607 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm_gpu(x_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPvqNWkQW-BM"
      },
      "source": [
        "# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "FaPKGO5aW-BN"
      },
      "outputs": [],
      "source": [
        "# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n",
        "# справедлива и обратная ситуация\n",
        "\n",
        "# выскочит ошибка\n",
        "# посмотрите на нее, возможно, вы еще встретитесь\n",
        "# pred = lstm_gpu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NX5HHDOW-BO"
      },
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKr22rklW-BP"
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bny8SvCgW-BQ"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vc-bLok2W-BQ"
      },
      "outputs": [],
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHpit-1tW-BR",
        "outputId": "38e9f271-0c7e-49dd-ce3c-fed18ac02f36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ru_WzGSJW-BS"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHdBavTWW-BT",
        "outputId": "487a60be-58e7-43e4-b584-91db19de42aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcxv55j7W-BV",
        "outputId": "1312a3d9-f22f-4697-f8bc-95940b05b9f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmJt6cqkW-BW"
      },
      "source": [
        "## Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyM8Xl24W-BX",
        "outputId": "8a2eac62-54f1-48af-bd06-e3ee5b1e7d12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grPNMjEZW-BY"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "btJ-ApiOW-BY"
      },
      "outputs": [],
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "QIYff7YyW-Bb"
      },
      "outputs": [],
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tVn6YKLW-Bd",
        "outputId": "00a4b188-80c9-48fd-a5ca-3d1d550ba41e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N4w6-iWW-Be",
        "outputId": "2871a525-852e-49e4-c7e6-67365106bc3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-C3_phaW-Bf",
        "outputId": "5bcc82ce-f589-4151-eab1-d9bf7e52243f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stBQ3yhqW-Bi"
      },
      "source": [
        "# Подготовим данные в DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vPX_m5M4W-Bi"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV76BdN0W-Bj",
        "outputId": "d57cac08-7d89-4ba2-efad-050c1a00cf20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "'UNK' in word2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "INB_dPAnW-Bk",
        "outputId": "8304a4dc-8866-4887-c1ea-e90fd546a441"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75b29c3a-5ad4-45dc-9984-6bb682e7d1a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75b29c3a-5ad4-45dc-9984-6bb682e7d1a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75b29c3a-5ad4-45dc-9984-6bb682e7d1a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75b29c3a-5ad4-45dc-9984-6bb682e7d1a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qv1mKAeW-Bl"
      },
      "source": [
        "# Замапим категории в индексы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "iHeFzZe1W-Bl"
      },
      "outputs": [],
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3x9QhXYW-Bn",
        "outputId": "6a9cf359-b557-4f92-9783-51ce50fbbe5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'law': 1, 'love': 2, 'relax': 3, 'food': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "cat_mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ef--8SWbW-Bo"
      },
      "outputs": [],
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc48ALg_W-Bp"
      },
      "source": [
        "# Читалка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFIQEv6nvE4c"
      },
      "source": [
        "## Что происходит ниже\n",
        "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "1. Загружаем данные:\n",
        "    1. Проходимся по датасету\n",
        "    1. Предобрабатываем каждый текст в датасете\n",
        "    1. Индексируем его\n",
        "    1. Паддим до нужной длины\n",
        "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ZkX8SC_sW-Bp"
      },
      "outputs": [],
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "        \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            \n",
        "            words = self.process_text(text)\n",
        "            \n",
        "            indexed_words = self.indexing(words)\n",
        "            \n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "R3WW8V9lyLm0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnc2nD8gW-Br",
        "outputId": "e589180f-cf23-425f-91eb-d163cc1bfd7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [00:02<00:00, 98772.63it/s]\n",
            "Loading data: 100%|██████████| 23778/23778 [00:00<00:00, 122239.06it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dGeftxdgW-Br"
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkGQffBW-Bs",
        "outputId": "816d193b-7c8b-40f8-ba7a-ed4e1e97a577"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   56,  4250,    10,  ...,     0,     0,     0],\n",
              "        [   24,    56,    89,  ...,     0,     0,     0],\n",
              "        [ 6036,  2200,  1242,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [   19,   645,    75,  ...,     0,     0,     0],\n",
              "        [   74, 25593,     8,  ...,     0,     0,     0],\n",
              "        [ 8078,   322,     3,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxUk4nGcW-Bt",
        "outputId": "dd9e71cd-d88d-4033-d193-c80536073727"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 0, 3, 1, 4, 0, 3, 3, 0, 1, 4, 1, 4, 3, 1, 4, 1, 3, 0, 0, 0, 4, 4,\n",
              "        2, 1, 1, 4, 1, 3, 3, 4, 2, 3, 0, 1, 0, 3, 4, 4, 1, 3, 3, 4, 1, 4, 1, 1,\n",
              "        2, 1, 0, 0, 3, 4, 3, 0, 1, 2, 3, 0, 0, 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy0dkkTIW-Bw"
      },
      "source": [
        "# Обучить нейронку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "3wwkxZm1vE43"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "\n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "        self.LSTM = torch.nn.LSTM(input_size = 300, \n",
        "                                  hidden_size = 256,\n",
        "                                  num_layers=2, \n",
        "                                  batch_first=True, \n",
        "                                  dropout=0.1, \n",
        "                                  bidirectional=True)\n",
        "  \n",
        "        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)# три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "        \n",
        "        self.cnn_3gr = torch.nn.Conv1d(in_channels=256,  out_channels=128, kernel_size=3, stride=1) # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "        self.cnn_4gr = torch.nn.Conv1d(in_channels=256,  out_channels=128, kernel_size=4, stride=1)\n",
        "        self.cnn_5gr = torch.nn.Conv1d(in_channels=256,  out_channels=128, kernel_size=5, stride=1)\n",
        " \n",
        "        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True) # сверху накидываем два полносвязных слоя для классификации\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_2 = torch.nn.Linear(in_features=256, out_features=n, bias=True)\n",
        "\n",
        "        \n",
        "  def forward(self, x):\n",
        "      x_emb = self.emb_layer(x)#примените эмбеддинги\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) /  math.sqrt(x_q.size(-1))\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      attention_vectors = torch.bmm(att_dist, x_v)# тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "      \n",
        "      x =  self.linear_1(x_cat)# пару полносвязных слоев с релу для классификации\n",
        "      x = self.relu(x)    \n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "jFbyUXLE0WPv"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "OZgh4ONx0HvT"
      },
      "outputs": [],
      "source": [
        "model = model_with_att(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNO6VSbJgQ36",
        "outputId": "079710f3-850a-49f2-f07f-68dd1b321255"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "model #если сделать batch_first=True, то можно не транспонировать батчи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "E66MWNgM0QKM"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErboeQbv0dnC",
        "outputId": "6d56305a-b079-4c53-f087-f6b7d023ecd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "bL6zIZSt0h9W"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Vsxw4M2m0m2B"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "7rUTc0l60pV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8da73b3-9cd6-47ed-c3f0-ae5a22385ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [01:16<00:00, 2785.40it/s, train_loss=0.471]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.573, test - 0.476\n",
            "F1 test - 0.831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [01:14<00:00, 2880.55it/s, train_loss=0.434]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.453, test - 0.451\n",
            "F1 test - 0.838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [01:14<00:00, 2890.97it/s, train_loss=0.411]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.426, test - 0.441\n",
            "F1 test - 0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [01:14<00:00, 2870.10it/s, train_loss=0.388]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.403, test - 0.442\n",
            "F1 test - 0.843\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TMaPbh3oWwc"
      },
      "source": [
        "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "_aPjTQcR0vm2"
      },
      "outputs": [],
      "source": [
        "for instance in list(tqdm._instances): \n",
        "    tqdm._decr_instances(instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4gt2OWBqVzE"
      },
      "source": [
        "# Оценка\n",
        "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n",
        "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
        "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "SeeiJM_JIAsn"
      },
      "outputs": [],
      "source": [
        "#функция для тренировки. чтобы можно было менять параметры\n",
        "\n",
        "def train_parameters(train_loader, validation_loader, model, criterion, optimizer, losses = [], test_f1 = [], epochs = 10, best_test_loss = 10, early_stop_flag = True, scheduler = None):\n",
        "  for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "\n",
        "    if scheduler:\n",
        "      scheduler.step()\n",
        "\n",
        "    if early_stop_flag:\n",
        "      # Early stopping:\n",
        "      if mean_test_loss < best_test_loss:\n",
        "          best_test_loss = mean_test_loss\n",
        "      else:\n",
        "          print('Early stopping')\n",
        "          break\n",
        "  return losses, test_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "G5rPxx98O_kP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825a8a2a-7244-4d65-dfdc-9305a2a3e428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [01:14<00:00, 2872.87it/s, train_loss=0.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.567, test - 0.477\n",
            "F1 test - 0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [01:14<00:00, 2882.84it/s, train_loss=0.436]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.454, test - 0.455\n",
            "F1 test - 0.836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [01:14<00:00, 2860.26it/s, train_loss=0.412]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.427, test - 0.442\n",
            "F1 test - 0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [01:14<00:00, 2874.26it/s, train_loss=0.39]\n",
            "Epoch 2:  28%|██▊       | 59328/214001 [07:07<18:33, 138.90it/s, train_loss=0.462] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.405, test - 0.438\n",
            "F1 test - 0.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [01:14<00:00, 2880.56it/s, train_loss=0.367]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.383, test - 0.443\n",
            "F1 test - 0.844\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "#эксперименты\n",
        "\n",
        "model = model_with_att(vectors, n_classes)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "losses, test_f1 = train_parameters(train_loader, validation_loader, model, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Немного повысилось, попробуем scheduler, количество эпох не будем увеличивать из-за early stop'a"
      ],
      "metadata": {
        "id": "eDJsTjtSRg2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "USzXPmi1FsTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdafd5b-2cf0-4879-ae9c-30e3af9aabcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [01:13<00:00, 2913.56it/s, train_loss=0.469]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.570, test - 0.482\n",
            "F1 test - 0.829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [01:14<00:00, 2869.52it/s, train_loss=0.435]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.454, test - 0.453\n",
            "F1 test - 0.836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [01:14<00:00, 2858.87it/s, train_loss=0.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.426, test - 0.445\n",
            "F1 test - 0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [01:14<00:00, 2866.18it/s, train_loss=0.388]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.404, test - 0.441\n",
            "F1 test - 0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [01:14<00:00, 2877.04it/s, train_loss=0.363]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.381, test - 0.457\n",
            "F1 test - 0.841\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "model = model_with_att(vectors, n_classes)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "\n",
        "losses, test_f1 = train_parameters(train_loader, validation_loader, model, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_with_att(vectors, n_classes)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.2)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "\n",
        "losses, test_f1 = train_parameters(train_loader, validation_loader, model, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUvIvZmHn8Mn",
        "outputId": "cf266b2f-fe57-4be4-9792-05d264719d39"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [01:16<00:00, 2809.70it/s, train_loss=0.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.570, test - 0.480\n",
            "F1 test - 0.828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [01:14<00:00, 2885.23it/s, train_loss=0.435]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.454, test - 0.454\n",
            "F1 test - 0.836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [01:13<00:00, 2894.59it/s, train_loss=0.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.426, test - 0.443\n",
            "F1 test - 0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [01:13<00:00, 2899.09it/s, train_loss=0.387]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.404, test - 0.440\n",
            "F1 test - 0.843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [01:14<00:00, 2878.59it/s, train_loss=0.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.381, test - 0.450\n",
            "F1 test - 0.843\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_with_att(vectors, n_classes)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.002)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.2)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "losses, test_f1 = train_parameters(train_loader, validation_loader, model, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buJ7L4XvZM8n",
        "outputId": "caee6021-4451-48cd-bb49-fa1727da6558"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [01:13<00:00, 2929.68it/s, train_loss=0.463]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.550, test - 0.467\n",
            "F1 test - 0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [01:14<00:00, 2881.05it/s, train_loss=0.423]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.443, test - 0.449\n",
            "F1 test - 0.837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [01:14<00:00, 2876.47it/s, train_loss=0.391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.411, test - 0.441\n",
            "F1 test - 0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [01:15<00:00, 2844.63it/s, train_loss=0.359]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.381, test - 0.450\n",
            "F1 test - 0.842\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_with_att(vectors, n_classes)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.003)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "losses, test_f1 = train_parameters(train_loader, validation_loader, model, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ubFw-4lam4v",
        "outputId": "8514b22a-2948-4e79-b9f6-ee0e5e93fd1c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [01:14<00:00, 2882.00it/s, train_loss=0.463]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.551, test - 0.464\n",
            "F1 test - 0.836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [01:16<00:00, 2799.86it/s, train_loss=0.419]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.441, test - 0.441\n",
            "F1 test - 0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [01:14<00:00, 2877.26it/s, train_loss=0.381]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.409, test - 0.437\n",
            "F1 test - 0.845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [01:14<00:00, 2885.91it/s, train_loss=0.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.369, test - 0.446\n",
            "F1 test - 0.845\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "Rju5NGK-df9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "Mij4-u3siA7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Y8iNOC-iiTLv",
        "outputId": "ef09e79c-7a47-4abd-c208-64e1fcc8fe98"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0              0  Могут ли в россельхозбанке дать в залог норков...\n",
              "1              1  Может ли срочник перевестись на контракт после...\n",
              "2              0  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3              0  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4              1                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774         3                                  елку нарядили? =)\n",
              "237775         1  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776         4  Попробовала варить рис с половиной кубика для ...\n",
              "237777         4  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778         0  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3f127fa-dd7d-48ce-b4db-afed72255983\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>3</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>1</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>4</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>4</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>0</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3f127fa-dd7d-48ce-b4db-afed72255983')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3f127fa-dd7d-48ce-b4db-afed72255983 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3f127fa-dd7d-48ce-b4db-afed72255983');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = data.text.values\n",
        "labels = data.category.values"
      ],
      "metadata": {
        "id": "KD5kNT8uiRvx"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "779afefc6e7b4cea8b7ddc8ceb2aec1a",
            "439b058753ee4b918a849bbb2a4f8059",
            "adca1444fd0a40458e8e4ce16ae3c000",
            "a73db3bfb4aa451cbbd28e1606d5f5fa",
            "47ae142dfedf42288d2a99c072e5e7b9",
            "9a1a69000a024d06a43f2412f8687c84",
            "19a9407c4f4447d6a576d330738633e2",
            "71138a9f7f2b4bc9b0a62add2c089f2e",
            "268414c1e35b409da8fdbe589a7866f5",
            "8e838cb6a86b4ea3b4b485244b4ee18b",
            "fc6ce46c81fb4565b88c56c1288b8e7a",
            "08085ad4b6de482791d20df11678d7a0",
            "f98fc0ffa6b84711b8e24620a20ffc99",
            "645de97ecfb44e1bb7232decd7051b38",
            "31243e0aa72b4c8882442078bf51986c",
            "58adc86d7f65423898c4596e9be8a047",
            "cd5d5753a5e64c83925c85436e453301",
            "1f8eabaf36834c4eafb94238aeca6d67",
            "c1d591990d974f1e8bbaccf570a6d0ba",
            "b6733d1c50d54cca95cdca72c5b6ff1b",
            "e0514a760f1247deb8bfc86d9c3f5758",
            "9f5ca3af584d42cc80ec61fca11d5ba1",
            "c2001b1cb056401daeed6b5ae6fdffa6",
            "e3ef8470178943388ba6480615bcd83b",
            "ce5b96c4ba48462fbd2a37332f40da95",
            "ad32880f4ad64779863d7d4e8626396b",
            "39f96dad68a24591ad43b440cf5fc2d6",
            "f3ce38519c584bbcb4669106cb58aabe",
            "23e20625bcaa4d49af3e73bd1e116dfe",
            "cb28749a01c64a83804018f7d4d56459",
            "b1bf4787199b4386b77fcc8ce01ed917",
            "df15137c6c6c45d29e8236eb577b7ada",
            "f7754a18845945539e411bfa79e536cb"
          ]
        },
        "id": "QJd2pb7liIXr",
        "outputId": "97186aba-d482-4305-f003-768e32bac86c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/872k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "779afefc6e7b4cea8b7ddc8ceb2aec1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08085ad4b6de482791d20df11678d7a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2001b1cb056401daeed6b5ae6fdffa6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzXu9VYpiLXA",
        "outputId": "31d0ba7e-b217-4704-d9ea-1f4b1487313e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Tokenized:  ['могут', 'ли', 'в', 'рос', '##сель', '##хо', '##з', '##бан', '##ке', 'да', '##ть', 'в', 'зал', '##ог', 'но', '##рк', '##овых', 'ш', '##уб', 'пом', '##оги', '##те', 'по', '##жал', '##уи', '##ста']\n",
            "Token IDs:  [22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in tqdm(sentences):\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo1QJvQUi3Jg",
        "outputId": "753edf8b-8ce0-4069-e9b0-7087119ed7fb"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   3%|▎         | 7296/214001 [1:24:30<39:54:06,  1.44it/s, train_loss=1.32]\n",
            "100%|██████████| 237779/237779 [02:15<00:00, 1757.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Token IDs: [101, 22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294, 102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD54A7AejABh",
        "outputId": "019830a1-6ab7-46ed-e13b-3d6f975c2717"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 97\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oJpqO8WjDNU",
        "outputId": "d04717fa-1784-4ed9-cdaf-4db7ef45646c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 97 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "metadata": {
        "id": "egSjFQQJjbNJ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "metadata": {
        "id": "gKsubSf0jcRe"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "fdbdrniGkFnj"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "qOhedIGikLon"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7e27f9e966a842b9b35d76e647fe1573",
            "2c3626b3f2994f9e8b7e7d3daea99010",
            "95283b93ab5a4143b4cfe98b9fa3eb71",
            "fae2d910d2084ac2abb226c51f868c28",
            "b89aa819281d4bfa8e367bf65b662335",
            "854e2e35e33e403dbf939f1eb414e8d5",
            "71d81c267f544862be9575471cd5b1a7",
            "dc759f34911b4f2b9a177ad0e6d95cf3",
            "634bf5b39edd441f94e321de84a8f6fe",
            "9117bb82d84f410a9df175b2ded76cf6",
            "0ec82e7a9dc84e94893b068f122c2e24"
          ]
        },
        "id": "YS41pQ3DkN_R",
        "outputId": "f53a7870-54d3-45b0-fd5f-552a401a9f29"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/672M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e27f9e966a842b9b35d76e647fe1573"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = model.bert.pooler.dense.weight\n",
        "c = model.classifier.weight\n",
        "b = b.cpu().detach().numpy()\n",
        "c = c.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "ENv5yxofkYNo"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHpwXPR5kdCC",
        "outputId": "613a2c07-9a29-4b22-d172-76a70890740b"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (105879, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qBnkO6okiqK",
        "outputId": "4cdc87e6-c210-4242-c74b-8d9a1720ec0a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 100, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "Rlv7platkixd"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#функция для подсчета F1\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate f1 score of our predictions vs labels\n",
        "def f1_score_flat(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, pred_flat, average='micro')"
      ],
      "metadata": {
        "id": "vU3SqgMCknU6"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "bk4x4_d6lKTS"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_f1 = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_f1 = f1_score_flat(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_f1 += tmp_eval_f1 \n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  F1 score: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdT9sYFIlWvx",
        "outputId": "797d0020-518e-41de-f071-10fc21b246a4"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:36.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:01:12.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:50.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:02:28.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:03:05.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:03:43.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:04:20.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:04:58.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:05:36.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:06:13.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:06:51.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:07:29.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:08:06.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:08:44.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:09:22.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:09:59.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:10:37.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:11:14.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:11:52.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:12:30.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:13:07.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:13:45.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:14:23.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:15:00.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:15:38.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:16:15.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:16:53.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:17:31.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:18:08.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:18:46.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:19:24.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:20:01.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:20:39.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:21:16.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:21:54.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:22:32.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:23:09.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:23:47.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:24:24.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:25:02.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:25:40.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:26:17.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:26:55.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:27:33.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:28:10.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:28:48.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:29:26.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:30:03.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:30:41.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:31:19.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:31:56.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:32:34.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:33:11.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:33:49.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:34:27.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:35:04.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:35:42.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:36:20.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:36:57.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:37:35.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:38:13.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:38:50.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:39:28.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:40:05.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:40:43.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:41:21.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:41:58.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:42:36.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:43:14.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:43:51.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:44:29.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:45:06.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:45:44.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:46:22.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:46:59.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:47:37.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:48:14.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:48:52.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:49:30.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:50:07.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:50:45.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:51:22.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:52:00.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 0:52:23\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.85\n",
            "  Validation took: 0:02:07\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:38.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:01:15.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:53.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:02:30.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:03:08.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:03:46.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:04:23.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:05:01.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:05:39.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:06:16.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:06:54.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:07:32.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:08:09.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:08:47.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:09:24.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:10:02.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:10:40.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:11:17.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:11:55.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:12:33.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:13:10.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:13:48.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:14:25.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:15:03.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:15:41.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:16:18.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:16:56.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:17:34.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:18:11.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:18:49.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:19:26.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:20:04.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:20:42.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:21:19.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:21:57.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:22:34.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:23:12.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:23:50.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:24:27.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:25:05.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:25:43.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:26:20.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:26:58.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:27:35.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:28:13.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:28:51.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:29:28.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:30:06.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:30:44.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:31:21.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:31:59.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:32:36.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:33:14.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:33:52.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:34:29.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:35:07.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:35:44.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:36:22.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:37:00.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:37:37.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:38:15.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:38:53.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:39:30.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:40:08.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:40:45.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:41:23.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:42:01.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:42:38.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:43:16.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:43:54.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:44:31.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:45:09.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:45:46.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:46:24.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:47:02.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:47:39.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:48:17.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:48:55.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:49:32.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:50:10.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:50:48.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:51:25.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:52:03.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:52:25\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.85\n",
            "  Validation took: 0:02:07\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:38.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:01:15.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:53.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:02:30.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:03:08.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:03:46.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:04:23.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:05:01.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:05:39.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:06:16.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:06:54.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:07:31.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:08:09.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:08:47.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:09:24.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:10:02.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:10:40.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:11:17.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:11:55.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:12:33.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:13:10.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:13:48.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:14:25.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:15:03.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:15:41.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:16:18.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:16:56.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:17:34.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:18:11.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:18:49.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:19:27.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:20:04.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:20:42.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:21:20.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:21:57.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:22:35.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:23:13.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:23:50.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:24:28.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:25:06.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:25:43.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:26:21.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:26:58.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:27:36.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:28:14.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:28:51.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:29:29.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:30:07.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:30:44.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:31:22.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:32:00.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:32:37.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:33:15.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:33:53.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:34:30.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:35:08.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:35:46.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:36:23.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:37:01.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:37:38.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:38:16.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:38:54.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:39:31.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:40:09.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:40:47.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:41:24.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:42:02.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:42:39.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:43:17.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:43:55.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:44:32.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:45:10.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:45:48.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:46:25.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:47:03.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:47:41.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:48:18.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:48:56.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:49:34.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:50:11.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:50:49.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:51:26.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:52:04.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:52:26\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.86\n",
            "  Validation took: 0:02:07\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:38.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:01:15.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:53.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:02:31.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:03:08.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:03:46.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:04:24.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:05:01.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:05:39.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:06:17.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:06:54.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:07:32.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:08:09.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:08:47.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:09:25.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:10:02.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:10:40.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:11:18.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:11:55.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:12:33.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:13:11.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:13:48.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:14:26.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:15:03.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:15:41.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:16:19.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:16:56.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:17:34.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:18:12.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:18:49.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:19:27.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:20:05.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:20:42.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:21:20.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:21:58.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:22:35.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:23:13.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:23:51.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:24:28.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:25:06.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:25:43.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:26:21.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:26:59.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:27:36.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:28:14.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:28:52.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:29:29.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:30:07.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:30:45.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:31:22.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:32:00.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:32:38.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:33:15.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:33:53.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:34:30.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:35:08.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:35:46.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:36:23.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:37:01.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:37:38.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:38:16.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:38:54.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:39:31.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:40:09.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:40:47.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:41:24.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:42:02.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:42:39.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:43:17.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:43:55.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:44:32.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:45:10.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:45:48.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:46:25.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:47:03.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:47:41.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:48:18.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:48:56.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:49:34.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:50:11.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:50:49.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:51:26.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:52:04.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:52:26\n",
            "\n",
            "Running Validation...\n",
            "  F1 score: 0.86\n",
            "  Validation took: 0:02:07\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "779afefc6e7b4cea8b7ddc8ceb2aec1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_439b058753ee4b918a849bbb2a4f8059",
              "IPY_MODEL_adca1444fd0a40458e8e4ce16ae3c000",
              "IPY_MODEL_a73db3bfb4aa451cbbd28e1606d5f5fa"
            ],
            "layout": "IPY_MODEL_47ae142dfedf42288d2a99c072e5e7b9"
          }
        },
        "439b058753ee4b918a849bbb2a4f8059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a1a69000a024d06a43f2412f8687c84",
            "placeholder": "​",
            "style": "IPY_MODEL_19a9407c4f4447d6a576d330738633e2",
            "value": "Downloading: 100%"
          }
        },
        "adca1444fd0a40458e8e4ce16ae3c000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71138a9f7f2b4bc9b0a62add2c089f2e",
            "max": 871891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_268414c1e35b409da8fdbe589a7866f5",
            "value": 871891
          }
        },
        "a73db3bfb4aa451cbbd28e1606d5f5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e838cb6a86b4ea3b4b485244b4ee18b",
            "placeholder": "​",
            "style": "IPY_MODEL_fc6ce46c81fb4565b88c56c1288b8e7a",
            "value": " 872k/872k [00:00&lt;00:00, 1.59MB/s]"
          }
        },
        "47ae142dfedf42288d2a99c072e5e7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1a69000a024d06a43f2412f8687c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a9407c4f4447d6a576d330738633e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71138a9f7f2b4bc9b0a62add2c089f2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268414c1e35b409da8fdbe589a7866f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e838cb6a86b4ea3b4b485244b4ee18b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc6ce46c81fb4565b88c56c1288b8e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08085ad4b6de482791d20df11678d7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f98fc0ffa6b84711b8e24620a20ffc99",
              "IPY_MODEL_645de97ecfb44e1bb7232decd7051b38",
              "IPY_MODEL_31243e0aa72b4c8882442078bf51986c"
            ],
            "layout": "IPY_MODEL_58adc86d7f65423898c4596e9be8a047"
          }
        },
        "f98fc0ffa6b84711b8e24620a20ffc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd5d5753a5e64c83925c85436e453301",
            "placeholder": "​",
            "style": "IPY_MODEL_1f8eabaf36834c4eafb94238aeca6d67",
            "value": "Downloading: 100%"
          }
        },
        "645de97ecfb44e1bb7232decd7051b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d591990d974f1e8bbaccf570a6d0ba",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6733d1c50d54cca95cdca72c5b6ff1b",
            "value": 28
          }
        },
        "31243e0aa72b4c8882442078bf51986c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0514a760f1247deb8bfc86d9c3f5758",
            "placeholder": "​",
            "style": "IPY_MODEL_9f5ca3af584d42cc80ec61fca11d5ba1",
            "value": " 28.0/28.0 [00:00&lt;00:00, 277B/s]"
          }
        },
        "58adc86d7f65423898c4596e9be8a047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd5d5753a5e64c83925c85436e453301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8eabaf36834c4eafb94238aeca6d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1d591990d974f1e8bbaccf570a6d0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6733d1c50d54cca95cdca72c5b6ff1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0514a760f1247deb8bfc86d9c3f5758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5ca3af584d42cc80ec61fca11d5ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2001b1cb056401daeed6b5ae6fdffa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3ef8470178943388ba6480615bcd83b",
              "IPY_MODEL_ce5b96c4ba48462fbd2a37332f40da95",
              "IPY_MODEL_ad32880f4ad64779863d7d4e8626396b"
            ],
            "layout": "IPY_MODEL_39f96dad68a24591ad43b440cf5fc2d6"
          }
        },
        "e3ef8470178943388ba6480615bcd83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3ce38519c584bbcb4669106cb58aabe",
            "placeholder": "​",
            "style": "IPY_MODEL_23e20625bcaa4d49af3e73bd1e116dfe",
            "value": "Downloading: 100%"
          }
        },
        "ce5b96c4ba48462fbd2a37332f40da95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb28749a01c64a83804018f7d4d56459",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1bf4787199b4386b77fcc8ce01ed917",
            "value": 625
          }
        },
        "ad32880f4ad64779863d7d4e8626396b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df15137c6c6c45d29e8236eb577b7ada",
            "placeholder": "​",
            "style": "IPY_MODEL_f7754a18845945539e411bfa79e536cb",
            "value": " 625/625 [00:00&lt;00:00, 9.47kB/s]"
          }
        },
        "39f96dad68a24591ad43b440cf5fc2d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ce38519c584bbcb4669106cb58aabe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23e20625bcaa4d49af3e73bd1e116dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb28749a01c64a83804018f7d4d56459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1bf4787199b4386b77fcc8ce01ed917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df15137c6c6c45d29e8236eb577b7ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7754a18845945539e411bfa79e536cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e27f9e966a842b9b35d76e647fe1573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c3626b3f2994f9e8b7e7d3daea99010",
              "IPY_MODEL_95283b93ab5a4143b4cfe98b9fa3eb71",
              "IPY_MODEL_fae2d910d2084ac2abb226c51f868c28"
            ],
            "layout": "IPY_MODEL_b89aa819281d4bfa8e367bf65b662335"
          }
        },
        "2c3626b3f2994f9e8b7e7d3daea99010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_854e2e35e33e403dbf939f1eb414e8d5",
            "placeholder": "​",
            "style": "IPY_MODEL_71d81c267f544862be9575471cd5b1a7",
            "value": "Downloading: 100%"
          }
        },
        "95283b93ab5a4143b4cfe98b9fa3eb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc759f34911b4f2b9a177ad0e6d95cf3",
            "max": 672271273,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_634bf5b39edd441f94e321de84a8f6fe",
            "value": 672271273
          }
        },
        "fae2d910d2084ac2abb226c51f868c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9117bb82d84f410a9df175b2ded76cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_0ec82e7a9dc84e94893b068f122c2e24",
            "value": " 672M/672M [00:11&lt;00:00, 44.3MB/s]"
          }
        },
        "b89aa819281d4bfa8e367bf65b662335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854e2e35e33e403dbf939f1eb414e8d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d81c267f544862be9575471cd5b1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc759f34911b4f2b9a177ad0e6d95cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634bf5b39edd441f94e321de84a8f6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9117bb82d84f410a9df175b2ded76cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ec82e7a9dc84e94893b068f122c2e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}